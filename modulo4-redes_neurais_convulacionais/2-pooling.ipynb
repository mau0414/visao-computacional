{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pooling é o processo de diminuir o tamanho de uma imagem, importante para\n",
    "\n",
    "1. Reduzir custo computacional de processar imagens muito grandes\n",
    "2. Capturar características de uma imagem em múltiplas escalas\n",
    "3. Na classificação, deseja-se que a saída de uma rede seja um único valor, o que é feito aos poucos reduzindo o tamanho da imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn # blocos basicos de construcao de grafos, como camadas lineares\n",
    "import torch.nn.functional as F # colecao de funcoes para construir redes neurais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "           [ 4.,  5.,  6.,  7.],\n",
       "           [ 8.,  9., 10., 11.],\n",
       "           [12., 13., 14., 15.]]]]),\n",
       " tensor([[[[ 5.,  6.,  7.],\n",
       "           [ 9., 10., 11.],\n",
       "           [13., 14., 15.]]]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 batch de uma imagem 16x16 com um unico canal\n",
    "x = torch.arange(0, 16).float().reshape(1, 1, 4, 4)\n",
    "\n",
    "# operacao funciona com divisao em janelas 2x2 (kernel_size) na matriz x e pega-se o maior valor em cada\n",
    "# janela (9 janelas no total, gerando 9 escolhas e por isso matriz 3x3)\n",
    "y = F.max_pool2d(x, kernel_size=2, stride=1)\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# por padrao o stride = kernel_size, o que diminuiria imagem pela metade\n",
    "y = F.max_pool2d(x, kernel_size=2)\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 2.5000,  4.5000],\n",
       "          [10.5000, 12.5000]]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# outra operacao eh pegar media da janela ao inves do maior valor possivel\n",
    "y = F.avg_pool2d(x, kernel_size=2)\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 2.5000,  4.5000],\n",
      "          [10.5000, 12.5000]]]])\n"
     ]
    }
   ],
   "source": [
    "# A operação acima é equivalente a convoluir a imagem com o seguinte filtro de média:\n",
    "w = torch.tensor([[1,1],[1,1]])/4\n",
    "w = w.reshape(1,1,2,2)\n",
    "\n",
    "y = F.conv2d(x, w, stride=2)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 2.5000,  3.5000,  4.5000],\n",
       "          [ 6.5000,  7.5000,  8.5000],\n",
       "          [10.5000, 11.5000, 12.5000]]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# padding adaptativo: permite fixar tamanho da saida para que o kernel_size, padding e stride se adaptem\n",
    "# de forma que a saida tenha o tamanho passado\n",
    "\n",
    "F.adaptive_avg_pool2d(x, output_size=(3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 112, 112]),\n",
       " torch.Size([1, 3, 56, 56]),\n",
       " torch.Size([1, 3, 5, 5]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# camadas de pooling: funcoes acima sao implementadas como camadas\n",
    "\n",
    "pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "pool3 = nn.AdaptiveAvgPool2d(output_size=(5,5))\n",
    "\n",
    "x = torch.rand((1, 3, 224, 224))\n",
    "y1 = pool1(x)\n",
    "y2 = pool2(y1)\n",
    "y3 = pool3(y2)\n",
    "\n",
    "\n",
    "y1.shape, y2.shape, y3.shape\n",
    "\n",
    "# camadas de pool nao tem parametros treinaveis que podem ser otimizados durante treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vc2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
